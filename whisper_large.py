import openai
import argparse
import opencc
from pathlib import Path
converter = opencc.OpenCC('t2s')  # ç¹ä½“è½¬ç®€ä½“

def transcribe_audio(base_url: str, model_id: str, audio_path: str):
    """ä½¿ç”¨OpenAIå…¼å®¹APIè¿›è¡Œè¯­éŸ³è¯†åˆ«"""
    try:
        # åˆå§‹åŒ–å®¢æˆ·ç«¯ (api_keyå¯ä»¥æ˜¯ä»»æ„å­—ç¬¦ä¸²ï¼Œä½†ä¸èƒ½ä¸ºç©º)
        client = openai.Client(api_key="not empty", base_url=base_url)
        print(f"âœ… æˆåŠŸè¿æ¥åˆ°è¯­éŸ³è¯†åˆ«æœåŠ¡: {base_url}")

        # éªŒè¯éŸ³é¢‘æ–‡ä»¶å­˜åœ¨
        audio_file = Path(audio_path)
        if not audio_file.is_file():
            raise FileNotFoundError(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")

        print(f"ğŸ”Š å·²åŠ è½½éŸ³é¢‘æ–‡ä»¶: {audio_path} (å¤§å°: {audio_file.stat().st_size / 1024:.2f} KB)")

        # æ‰§è¡Œè¯­éŸ³è¯†åˆ«
        print("ğŸ”„ æ­£åœ¨è¯†åˆ«éŸ³é¢‘...")

        with open(audio_file, "rb") as f:
            result = client.audio.transcriptions.create(
                model=model_id,
                file=f,
                language="chinese",
                prompt="ç”¨ç®€ä½“ä¸­æ–‡è¾“å‡º-simplified"
            )
        simplified_text = converter.convert(result.text)
        # è¿”å›è¯†åˆ«ç»“æœ
        print("\nğŸ™ï¸ è¯†åˆ«ç»“æœ:")
        print(simplified_text)
        return simplified_text

    except Exception as e:
        print(f"âŒ å‘ç”Ÿé”™è¯¯: {str(e)}")
        return None


if __name__ == "__main__":
    # è®¾ç½®é»˜è®¤å‚æ•°ï¼ˆæ ¹æ®ä½ çš„å®é™…æƒ…å†µä¿®æ”¹ï¼‰
    DEFAULT_ENDPOINT = "http://192.168.10.196:9997/v1"  # æ³¨æ„æ·»åŠ äº†/v1
    DEFAULT_MODEL_ID = "whisper-large-v3"
    DEFAULT_AUDIO = "part4.mp3"  # é»˜è®¤éŸ³é¢‘æ–‡ä»¶è·¯å¾„

    # åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨
    parser = argparse.ArgumentParser(description="OpenAIå…¼å®¹APIè¯­éŸ³è¯†åˆ«å®¢æˆ·ç«¯")
    parser.add_argument("--endpoint", default=DEFAULT_ENDPOINT,
                        help=f"APIæœåŠ¡åœ°å€ (é»˜è®¤: {DEFAULT_ENDPOINT})")
    parser.add_argument("--model", default=DEFAULT_MODEL_ID,
                        help=f"æ¨¡å‹ID (é»˜è®¤: {DEFAULT_MODEL_ID})")
    parser.add_argument("--audio", default=DEFAULT_AUDIO,
                        help=f"éŸ³é¢‘æ–‡ä»¶è·¯å¾„ (é»˜è®¤: {DEFAULT_AUDIO})")

    args = parser.parse_args()

    # æ‰“å°å¯åŠ¨ä¿¡æ¯
    print("\n" + "=" * 50)
    print(f"OpenAIå…¼å®¹APIè¯­éŸ³è¯†åˆ«å®¢æˆ·ç«¯å¯åŠ¨")
    print(f"æœåŠ¡åœ°å€: {args.endpoint}")
    print(f"ä½¿ç”¨æ¨¡å‹: {args.model}")
    print(f"å¤„ç†æ–‡ä»¶: {args.audio}")
    print("=" * 50 + "\n")

    # æ‰§è¡Œè¯­éŸ³è¯†åˆ«
    transcribe_audio(args.endpoint, args.model, args.audio)